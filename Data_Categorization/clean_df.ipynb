{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'processed_data_categorized.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Carregar o arquivo CSV\u001b[39;00m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_data_categorized.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Remover as colunas especificadas\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidated_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentities\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoctor_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhospital_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32md:\\OneDrive - InMotion - Consulting\\DocPlanner\\Bc\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\OneDrive - InMotion - Consulting\\DocPlanner\\Bc\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\OneDrive - InMotion - Consulting\\DocPlanner\\Bc\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\OneDrive - InMotion - Consulting\\DocPlanner\\Bc\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\OneDrive - InMotion - Consulting\\DocPlanner\\Bc\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'processed_data_categorized.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o arquivo CSV\n",
    "file_path = \"processed_data_categorized.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remover as colunas especificadas\n",
    "df = df.drop(columns=['validated_sentiment', 'entities', 'doctor_name', 'hospital_name', 'location'])\n",
    "\n",
    "# Salvar o DataFrame de volta no arquivo CSV\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"Colunas removidas e arquivo salvo com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de dados dividida em duas partes:\n",
      "processed_data_part1.csv\n",
      "processed_data_part2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o arquivo CSV\n",
    "file_path = \"processed_data_categorized.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Determinar o ponto de divisão\n",
    "half_size = len(df) // 2\n",
    "\n",
    "# Dividir a base em duas partes iguais\n",
    "df_part1 = df.iloc[:half_size]\n",
    "df_part2 = df.iloc[half_size:]\n",
    "\n",
    "# Salvar as duas partes em arquivos separados\n",
    "df_part1_path = \"processed_data_part1.csv\"\n",
    "df_part2_path = \"processed_data_part2.csv\"\n",
    "\n",
    "df_part1.to_csv(df_part1_path, index=False)\n",
    "df_part2.to_csv(df_part2_path, index=False)\n",
    "\n",
    "print(f\"Base de dados dividida em duas partes:\\n{df_part1_path}\\n{df_part2_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As colunas são iguais: True\n",
      "Quantidade de linhas em Part 1: 22425\n",
      "Quantidade de linhas em Part 2: 22426\n",
      "Valores nulos em Part 1: 3\n",
      "Valores nulos em Part 2: 15\n",
      "Linhas duplicadas em Part 1: 5\n",
      "Linhas duplicadas em Part 2: 3\n",
      "Comparação de estatísticas (média e desvio padrão) entre Part 1 e Part 2:\n",
      "     original_sentiment           cleaned_sentiment            \\\n",
      "                   self     other              self     other   \n",
      "mean           0.096869  0.190905          0.082053  0.210397   \n",
      "std            0.615894  0.638947          0.546750  0.605032   \n",
      "\n",
      "     sentiment_difference           original_length               \\\n",
      "                     self     other            self        other   \n",
      "mean             0.211678  0.190481      972.619621  1070.123874   \n",
      "std              0.309741  0.317607     1439.412095  1784.971623   \n",
      "\n",
      "     cleaned_length               \n",
      "               self        other  \n",
      "mean     512.567982   599.073486  \n",
      "std      871.299908  1197.958638  \n",
      "Diferença na distribuição categórica para a coluna 'country_code':\n",
      "                 Part1     Part2  Difference\n",
      "country_code                                \n",
      "br            0.982653  0.003344    0.979309\n",
      "de            0.017347  0.419201   -0.401854\n",
      "es            0.000000  0.577455   -0.577455\n",
      "Diferença na distribuição categórica para a coluna 'type':\n",
      "            Part1     Part2  Difference\n",
      "type                                   \n",
      "opinion  0.364058  0.313743    0.050315\n",
      "case     0.629521  0.680772   -0.051252\n",
      "Diferença na distribuição categórica para a coluna 'created_at':\n",
      "               Part1     Part2  Difference\n",
      "created_at                                \n",
      "2024-05-27  0.005485  0.016900   -0.011415\n",
      "2024-05-23  0.004771  0.015384   -0.010612\n",
      "Diferença na distribuição categórica para a coluna 'category_keywords':\n",
      "                              Part1     Part2  Difference\n",
      "category_keywords                                        \n",
      "Scheduling Issue           0.574448  0.627174   -0.052726\n",
      "General Issue              0.125039  0.084991    0.040048\n",
      "Wait Time Issue            0.126778  0.088781    0.037997\n",
      "Remote Consultation Issue  0.027380  0.043298   -0.015918\n",
      "Quality of Care            0.060424  0.043164    0.017259\n",
      "Staff Behavior             0.056009  0.078302   -0.022293\n",
      "Cost Issue                 0.004459  0.015161   -0.010702\n",
      "Diferença na distribuição categórica para a coluna 'category_bert':\n",
      "                    Part1     Part2  Difference\n",
      "category_bert                                  \n",
      "Wait Time Issue  0.419041  0.311870    0.107171\n",
      "Facility Issue   0.580914  0.688085   -0.107171\n",
      "Diferença na distribuição categórica para a coluna 'urgency_level':\n",
      "                  Part1     Part2  Difference\n",
      "urgency_level                                \n",
      "Low            0.638841  0.695487   -0.056647\n",
      "Medium         0.209543  0.143494    0.066049\n",
      "Diferença na distribuição categórica para a coluna 'resolution_suggestion':\n",
      "                          Part1     Part2  Difference\n",
      "resolution_suggestion                                \n",
      "Monitor                0.638841  0.695487   -0.056647\n",
      "Monitor Closely        0.209543  0.143494    0.066049\n",
      "Auditoria concluída.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar as duas partes\n",
    "df_part1 = pd.read_csv(\"processed_data_part1.csv\")\n",
    "df_part2 = pd.read_csv(\"processed_data_part2.csv\")\n",
    "\n",
    "# 1. Verificar se as colunas são iguais\n",
    "columns_equal = df_part1.columns.equals(df_part2.columns)\n",
    "print(f\"As colunas são iguais: {columns_equal}\")\n",
    "\n",
    "# 2. Comparar a quantidade de linhas\n",
    "rows_part1 = len(df_part1)\n",
    "rows_part2 = len(df_part2)\n",
    "print(f\"Quantidade de linhas em Part 1: {rows_part1}\")\n",
    "print(f\"Quantidade de linhas em Part 2: {rows_part2}\")\n",
    "\n",
    "# 3. Verificar valores nulos em ambas as partes\n",
    "nulls_part1 = df_part1.isnull().sum().sum()\n",
    "nulls_part2 = df_part2.isnull().sum().sum()\n",
    "print(f\"Valores nulos em Part 1: {nulls_part1}\")\n",
    "print(f\"Valores nulos em Part 2: {nulls_part2}\")\n",
    "\n",
    "# 4. Verificar duplicados em ambas as partes\n",
    "duplicates_part1 = df_part1.duplicated().sum()\n",
    "duplicates_part2 = df_part2.duplicated().sum()\n",
    "print(f\"Linhas duplicadas em Part 1: {duplicates_part1}\")\n",
    "print(f\"Linhas duplicadas em Part 2: {duplicates_part2}\")\n",
    "\n",
    "# 5. Verificar se as colunas numéricas têm a mesma média e desvio padrão\n",
    "numerical_columns = df_part1.select_dtypes(include=['number']).columns\n",
    "stats_part1 = df_part1[numerical_columns].describe().loc[['mean', 'std']]\n",
    "stats_part2 = df_part2[numerical_columns].describe().loc[['mean', 'std']]\n",
    "\n",
    "# Comparar estatísticas entre as partes\n",
    "stats_comparison = stats_part1.compare(stats_part2)\n",
    "print(\"Comparação de estatísticas (média e desvio padrão) entre Part 1 e Part 2:\")\n",
    "print(stats_comparison)\n",
    "\n",
    "# 6. Verificar se as colunas categóricas têm a mesma distribuição\n",
    "categorical_columns = df_part1.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    dist_part1 = df_part1[column].value_counts(normalize=True, sort=False)\n",
    "    dist_part2 = df_part2[column].value_counts(normalize=True, sort=False)\n",
    "    \n",
    "    # Realizar a comparação ignorando os índices\n",
    "    distribution_comparison = pd.concat([dist_part1, dist_part2], axis=1, keys=['Part1', 'Part2']).fillna(0)\n",
    "    distribution_comparison['Difference'] = distribution_comparison['Part1'] - distribution_comparison['Part2']\n",
    "    \n",
    "    # Mostrar somente diferenças significativas\n",
    "    differences = distribution_comparison[distribution_comparison['Difference'].abs() > 0.01]\n",
    "    if not differences.empty:\n",
    "        print(f\"Diferença na distribuição categórica para a coluna '{column}':\")\n",
    "        print(differences)\n",
    "\n",
    "print(\"Auditoria concluída.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>type</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content_en</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>original_sentiment</th>\n",
       "      <th>cleaned_sentiment</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>original_length</th>\n",
       "      <th>cleaned_length</th>\n",
       "      <th>category_keywords</th>\n",
       "      <th>category_bert</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>urgency_level</th>\n",
       "      <th>resolution_suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br</td>\n",
       "      <td>opinion</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>A doctor who is not very inclusive, it seems t...</td>\n",
       "      <td>doctor not_very inclusive seems want immediate...</td>\n",
       "      <td>-0.9209</td>\n",
       "      <td>-0.9126</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>1018</td>\n",
       "      <td>586</td>\n",
       "      <td>Scheduling Issue</td>\n",
       "      <td>Wait Time Issue</td>\n",
       "      <td>Critical</td>\n",
       "      <td>High</td>\n",
       "      <td>Immediate Action Required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>br</td>\n",
       "      <td>opinion</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>Although the online schedule showed availabili...</td>\n",
       "      <td>although online schedule showed availability t...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>154</td>\n",
       "      <td>110</td>\n",
       "      <td>Scheduling Issue</td>\n",
       "      <td>Facility Issue</td>\n",
       "      <td>Non-Critical</td>\n",
       "      <td>Low</td>\n",
       "      <td>Monitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>br</td>\n",
       "      <td>opinion</td>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>Didn't answer my wife. After traveling more th...</td>\n",
       "      <td>answer wife traveling three hour even though c...</td>\n",
       "      <td>-0.8079</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>246</td>\n",
       "      <td>156</td>\n",
       "      <td>General Issue</td>\n",
       "      <td>Wait Time Issue</td>\n",
       "      <td>Critical</td>\n",
       "      <td>High</td>\n",
       "      <td>Immediate Action Required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>br</td>\n",
       "      <td>opinion</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>\\nHe works at the Santo Amaro rehabilitation c...</td>\n",
       "      <td>work santo amaro rehabilitation center not_pre...</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-0.8027</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>624</td>\n",
       "      <td>416</td>\n",
       "      <td>Wait Time Issue</td>\n",
       "      <td>Facility Issue</td>\n",
       "      <td>Critical</td>\n",
       "      <td>High</td>\n",
       "      <td>Immediate Action Required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>br</td>\n",
       "      <td>opinion</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>This psychologist canceled the 1st appointment...</td>\n",
       "      <td>psychologist canceled st appointment wa late s...</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>-0.8729</td>\n",
       "      <td>1.2209</td>\n",
       "      <td>636</td>\n",
       "      <td>385</td>\n",
       "      <td>Scheduling Issue</td>\n",
       "      <td>Wait Time Issue</td>\n",
       "      <td>Critical</td>\n",
       "      <td>High</td>\n",
       "      <td>Immediate Action Required</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code     type  created_at  \\\n",
       "0           br  opinion  2024-04-06   \n",
       "1           br  opinion  2024-04-12   \n",
       "2           br  opinion  2024-04-22   \n",
       "3           br  opinion  2024-04-27   \n",
       "4           br  opinion  2024-04-29   \n",
       "\n",
       "                                          content_en  \\\n",
       "0  A doctor who is not very inclusive, it seems t...   \n",
       "1  Although the online schedule showed availabili...   \n",
       "2  Didn't answer my wife. After traveling more th...   \n",
       "3  \\nHe works at the Santo Amaro rehabilitation c...   \n",
       "4  This psychologist canceled the 1st appointment...   \n",
       "\n",
       "                                     cleaned_content  original_sentiment  \\\n",
       "0  doctor not_very inclusive seems want immediate...             -0.9209   \n",
       "1  although online schedule showed availability t...              0.0000   \n",
       "2  answer wife traveling three hour even though c...             -0.8079   \n",
       "3  work santo amaro rehabilitation center not_pre...             -1.0000   \n",
       "4  psychologist canceled st appointment wa late s...              0.3480   \n",
       "\n",
       "   cleaned_sentiment  sentiment_difference  original_length  cleaned_length  \\\n",
       "0            -0.9126                0.0083             1018             586   \n",
       "1             0.0000                0.0000              154             110   \n",
       "2            -0.5719                0.2360              246             156   \n",
       "3            -0.8027                0.1973              624             416   \n",
       "4            -0.8729                1.2209              636             385   \n",
       "\n",
       "  category_keywords    category_bert    issue_type urgency_level  \\\n",
       "0  Scheduling Issue  Wait Time Issue      Critical          High   \n",
       "1  Scheduling Issue   Facility Issue  Non-Critical           Low   \n",
       "2     General Issue  Wait Time Issue      Critical          High   \n",
       "3   Wait Time Issue   Facility Issue      Critical          High   \n",
       "4  Scheduling Issue  Wait Time Issue      Critical          High   \n",
       "\n",
       "       resolution_suggestion  \n",
       "0  Immediate Action Required  \n",
       "1                    Monitor  \n",
       "2  Immediate Action Required  \n",
       "3  Immediate Action Required  \n",
       "4  Immediate Action Required  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.concat([df_part1, df_part2], ignore_index=True)\n",
    "\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervalo de datas está correto: False\n",
      "Intervalo de datas: 2024-04-01 00:00:00 a 2024-06-30 00:00:00\n",
      "Dataset organizado em 12 semanas: False\n",
      "Número de semanas únicas: 13\n",
      "Países presentes estão corretos: True\n",
      "Países encontrados: {'es', 'br', 'de'}\n",
      "Total de registros é 43.251: False\n",
      "Total de registros: 44851\n"
     ]
    }
   ],
   "source": [
    "# Utilizando o DataFrame df_final criado anteriormente\n",
    "\n",
    "# 1. Verificar o intervalo de datas\n",
    "date_min = pd.to_datetime(df_final['created_at']).min()\n",
    "date_max = pd.to_datetime(df_final['created_at']).max()\n",
    "\n",
    "date_range_valid = date_min == '2024-04-01' and date_max == '2024-06-30'\n",
    "print(f\"Intervalo de datas está correto: {date_range_valid}\")\n",
    "print(f\"Intervalo de datas: {date_min} a {date_max}\")\n",
    "\n",
    "# 2. Verificar se está organizado em 12 semanas\n",
    "df_final['week_number'] = pd.to_datetime(df_final['created_at']).dt.isocalendar().week\n",
    "unique_weeks = df_final['week_number'].nunique()\n",
    "weeks_valid = unique_weeks == 12\n",
    "print(f\"Dataset organizado em 12 semanas: {weeks_valid}\")\n",
    "print(f\"Número de semanas únicas: {unique_weeks}\")\n",
    "\n",
    "# 3. Verificar a presença dos três países\n",
    "expected_countries = {'es', 'de', 'br'}\n",
    "actual_countries = set(df_final['country_code'].unique())\n",
    "countries_valid = actual_countries == expected_countries\n",
    "print(f\"Países presentes estão corretos: {countries_valid}\")\n",
    "print(f\"Países encontrados: {actual_countries}\")\n",
    "\n",
    "# 4. Verificar o total de registros\n",
    "total_records = len(df_final)\n",
    "total_records_valid = total_records == 43251\n",
    "print(f\"Total de registros é 43.251: {total_records_valid}\")\n",
    "print(f\"Total de registros: {total_records}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
